{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0422e70-5093-4a83-bae9-041840a7d5e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Using cached jiter-0.6.1-cp312-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.52.2-py3-none-any.whl (386 kB)\n",
      "Using cached jiter-0.6.1-cp312-none-win_amd64.whl (198 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "Successfully installed jiter-0.6.1 openai-1.52.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334326be-c0d2-4b98-961d-cfe256aac9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set up your OpenAI API Key\n",
    "\n",
    "api_key = \"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\"\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11ecfc40-e57f-49b9-a27b-2e2afd4491d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "# Set up Langchain API Key\n",
    "\n",
    "langchain_api_key = \"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\"\n",
    "langchain.api_key = langchain_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "902c9332-03fe-4755-9541-33d53820578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_project_key = \"GenAIAppWithOpenAI\"\n",
    "langchain.project_key = langchain_project_key\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db16cc8-2ee6-4276-b26e-54f7c40ef519",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-openai) (0.3.13)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.52.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-openai) (1.52.2)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (0.1.137)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain-openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain-openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.12->langchain-openai) (3.10.10)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.12->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.12->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.12->langchain-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.52.0->langchain-openai) (0.4.6)\n",
      "Using cached langchain_openai-0.2.3-py3-none-any.whl (49 kB)\n",
      "Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
      "Installing collected packages: tiktoken, langchain-openai\n",
      "Successfully installed langchain-openai-0.2.3 tiktoken-0.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b39521d7-ab75-4c5f-abbe-9587920934aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x000002993864D730> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002993864F440> root_client=<openai.OpenAI object at 0x0000029933C35610> root_async_client=<openai.AsyncOpenAI object at 0x000002993864D790> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(api_key = api_key,model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ef9491-8854-44a1-bd6a-6bbf53b2a4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence systems designed to create new content, such as text, images, music, or even complex data structures. Unlike traditional AI, which primarily focuses on recognizing patterns and making predictions based on existing data, generative AI models are capable of generating novel outputs that mimic the style, structure, or content of the data they were trained on.\\n\\nThe most well-known type of generative AI is the Generative Adversarial Network (GAN), which consists of two neural networks—the generator and the discriminator—that work together to produce content that is indistinguishable from real data. Another popular approach is the use of transformer-based models, like GPT (Generative Pre-trained Transformer), which are particularly effective in generating human-like text based on a given prompt.\\n\\nGenerative AI has a wide range of applications, including creating realistic images and videos, generating human-like text for chatbots, composing music, and even assisting in drug discovery by generating potential molecular structures. However, these technologies also raise ethical considerations, such as the potential for misuse in generating deepfakes or spreading misinformation.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 221, 'prompt_tokens': 13, 'total_tokens': 234, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90354628f2', 'finish_reason': 'stop', 'logprobs': None} id='run-8c1fc193-901b-492d-b958-8de851c04e6c-0' usage_metadata={'input_tokens': 13, 'output_tokens': 221, 'total_tokens': 234, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb47630-7dd6-48f2-a9d8-b581996b1094",
   "metadata": {},
   "source": [
    "* Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc812770-d0cb-4544-8441-59b123cc4086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are an expert AI Engineer. Provides me answer based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are an expert AI Engineer. Provides me answer based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b17e7e-6b5c-464b-a299-e237727a3c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Driverless cars, also known as autonomous vehicles (AVs), are equipped with technology that allows them to navigate and operate without human intervention. Here are some key components and models related to driverless car technology:\\n\\n1. **Key Technologies:**\\n   - **Sensors:** These include LiDAR (Light Detection and Ranging), radar, cameras, and ultrasonic sensors. They help the vehicle perceive its environment by detecting objects, measuring distances, and identifying road signs and markings.\\n   - **Machine Learning and AI:** Algorithms process data from sensors in real-time to make driving decisions. This includes path planning, object detection, and behavior prediction.\\n   - **Mapping and Localization:** High-definition maps and GPS are used to precisely locate the vehicle in its environment and plan routes.\\n   - **Control Systems:** These manage the vehicle's steering, acceleration, and braking to execute driving decisions safely.\\n\\n2. **Levels of Automation:**\\n   - **Level 0:** No automation; the driver controls everything.\\n   - **Level 1:** Driver Assistance, e.g., adaptive cruise control.\\n   - **Level 2:** Partial Automation, e.g., Tesla's Autopilot, where the car can steer and control speed but the driver must remain engaged.\\n   - **Level 3:** Conditional Automation, where the car can handle most tasks, but the driver must be ready to intervene.\\n   - **Level 4:** High Automation, where the car can handle all driving tasks in certain conditions without driver intervention.\\n   - **Level 5:** Full Automation, where no human intervention is required at any time.\\n\\n3. **Notable Models and Companies:**\\n   - **Waymo:** A subsidiary of Alphabet Inc., it's one of the leaders in autonomous vehicle technology, operating a fleet of self-driving taxis.\\n   - **Tesla:** Known for its Autopilot and Full Self-Driving (FSD) systems, which offer advanced driver assistance features.\\n   - **Cruise Automation:** A subsidiary of General Motors focusing on developing fully autonomous vehicles.\\n   - **Argo AI, Aurora, and Zoox:** Other key players in the autonomous vehicle industry working on delivering driverless car technology.\\n\\n4. **Challenges and Considerations:**\\n   - **Safety and Reliability:** Ensuring the vehicle can handle complex driving scenarios safely.\\n   - **Regulation and Legislation:** Developing a legal framework to govern the deployment and use of autonomous vehicles.\\n   - **Public Acceptance:** Building trust among consumers for widespread adoption.\\n   - **Ethical and Privacy Concerns:** Addressing issues related to data collection and decision-making in critical situations.\\n\\nDriverless cars are a rapidly advancing field, and ongoing research and development continue to push the boundaries of what's possible with autonomous driving technology.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 554, 'prompt_tokens': 36, 'total_tokens': 590, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90354628f2', 'finish_reason': 'stop', 'logprobs': None} id='run-3cc8c5c7-6dd2-46e3-ba4b-2b41633a036c-0' usage_metadata={'input_tokens': 36, 'output_tokens': 554, 'total_tokens': 590, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Chain -> combining multiple things\n",
    "\n",
    "chain = prompt|llm\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you pls tell me about driverless car model?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b0c622-b542-4bb9-a755-be9b67a20484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd84380-b4cd-43f3-8e18-2187e93c8bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform developed by LangChain to facilitate the debugging and evaluation of language models and applications built using them. It provides tools to help developers systematically assess the performance of their language model applications, identify issues, and improve them. Langsmith includes features for logging, monitoring, and analyzing the interactions between users and language models, which can be crucial for optimizing and ensuring the reliability of these applications. It is particularly useful for developers working with complex language processing tasks who need to ensure their models perform as expected in real-world scenarios.\n"
     ]
    }
   ],
   "source": [
    "## stroutput parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\":\"Can you pls tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39bd65-bb76-4082-820f-b2e4d8070069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
